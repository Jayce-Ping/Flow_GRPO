{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ec4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from itertools import chain, groupby\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1b20b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/T2IS/data_summary.jsonl\", \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Group by uid then (height, width)\n",
    "for d in data:\n",
    "    d['size'] = (d['height'], d['width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "67f61d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [d for d in data if sum(d['size']) < 512 * 5]\n",
    "# with open(\"dataset/T2IS/data_summary_less_than_5.jsonl\", \"w\") as f:\n",
    "#     for d in subdata:\n",
    "#         f.write(json.dumps(d) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "836eac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a4d6aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame(data[:int(len(data)*0.5)])\n",
    "test_set = pd.DataFrame(data[int(len(data)*0.5):])\n",
    "\n",
    "grouped_train = train_set.groupby(['uid', 'size'])\n",
    "grouped_test = test_set.groupby(['uid', 'size'])\n",
    "\n",
    "grouped_train = {\n",
    "    name: group.to_dict('records')\n",
    "    for name, group in grouped_train\n",
    "}\n",
    "grouped_test = {\n",
    "    name: group.to_dict('records')\n",
    "    for name, group in grouped_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "711c08d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 46)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grouped_train), len(grouped_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "62a6f3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12]),\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12])]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.unique([len(x) for x in grouped.values()]) for grouped in [grouped_train, grouped_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3ed1c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"dataset/T2IS/train_half_less_than_5\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(os.path.join(output_dir, \"train_metadata.jsonl\"), \"w\") as f:\n",
    "    for group in grouped_train.values():\n",
    "        for item in group:\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "with open(os.path.join(output_dir, \"test_metadata.jsonl\"), \"w\") as f:\n",
    "    for group in grouped_test.values():\n",
    "        for item in group:\n",
    "            f.write(json.dumps(item) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common-use",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
